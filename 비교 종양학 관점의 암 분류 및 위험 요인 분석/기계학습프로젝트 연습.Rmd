---
title: "기계학습 프로젝트"
author: "202201130_hyolim_Kim"
date: "2025-11-04"
output: html_document
---
#연구 계획서: 비교 종양학 관점의 암 분류 및 위험 요인 분석
#인간 유방암 데이터(Kaggle)와 반려견 림프종 데이터(Public)의 통합적 접근
```{r setup, include=FALSE}
knitr::opts_chunk$set(error = FALSE)
```

```{r error=FALSE}

# --- 0. 패키지 설치 및 라이브러리 로드 ---

# install.packages("tidyverse")
# install.packages("corrplot")
# install.packages("caret")
# install.packages("e1071")
# install.packages("randomForest")
# install.packages("pROC")

# 라이브러리 로드
library(tidyverse)    # 데이터 전처리 및 시각화 (ggplot2, dplyr 포함)
library(corrplot)     # 상관관계 히트맵
library(caret)        # 데이터 분리, 전처리, 모델 평가 (confusionMatrix)
library(e1071)        # SVM 모델
library(randomForest) # 랜덤 포레스트 모델
library(pROC)         # ROC-AUC 커브


# --- 1. 데이터 전처리 ---

# 1-1. 데이터 불러오기
# (업로드된 파일 이름 'data.csv' 기준)
data <- read.csv("C:/Users/김효림/OneDrive/바탕 화면/통계적기계학습및실습/data.csv")

# 1-2. 데이터 구조 확인 및 불필요한 변수 제거
# id: 분석에 불필요
# X: CSV 마지막 열의 쉼표(,)로 인해 생긴 빈 열일 가능성 높음
str(data)
data_cleaned <- data %>% 
  select(-id, -X) %>%              # id와 X 열 제거
  drop_na()                        # 혹시 모를 결측치(NA) 행 제거

# 1-3. 타겟 변수(diagnosis) 인코딩
# M(Malignant, 악성), B(Benign, 양성)을 Factor(범주형)로 변환
# 'Malignant'를 양성(Positive) 클래스로 설정 (caret의 'positive' 옵션용)
data_cleaned$diagnosis <- factor(data_cleaned$diagnosis, 
                                 levels = c("B", "M"),
                                 labels = c("Benign", "Malignant"))

str(data_cleaned$diagnosis)

# --- 2. 탐색적 데이터 분석 (EDA) ---

# 2-1. Boxplot (악성/양성 간 주요 피처 비교)
# 예: 'radius_worst' (가장 큰 반경)
ggplot(data_cleaned, aes(x = diagnosis, y = radius_worst, fill = diagnosis)) +
  geom_boxplot() +
  ggtitle("악성(Malignant) vs 양성(Benign)의 radius_worst 분포") +
  theme_minimal()

# 2-2. Correlation Heatmap (변수 간 상관관계)
# diagnosis를 제외한 숫자형 변수만 선택
numeric_features <- data_cleaned %>% 
  select(-diagnosis)

# 상관행렬 계산 및 시각화
cor_matrix <- cor(numeric_features)
corrplot(cor_matrix, method = "color", order = "hclust", tl.cex = 0.5)
# (결과: 많은 변수가 서로 강한 상관관계를 보임 -> PCA 적용 명분)

# --- 3. 모델링 및 평가 ---

# 3-1. Train / Test 데이터 분리 (80:20)
set.seed(123) # 결과 재현을 위한 시드 설정
trainIndex <- createDataPartition(data_cleaned$diagnosis, 
                                  p = 0.8, 
                                  list = FALSE)
trainData <- data_cleaned[trainIndex, ]
testData  <- data_cleaned[-trainIndex, ]

# 3-2. StandardScaler (데이터 표준화)
# 'diagnosis' 열을 제외한 모든 피처를 표준화
feature_names <- setdiff(names(trainData), "diagnosis")

# **중요**: trainData로 스케일러(scaler)를 만듭니다.
scaler <- preProcess(trainData[, feature_names], method = c("center", "scale"))

# trainData와 testData에 **동일한 스케일러**를 적용합니다.
trainData_scaled <- predict(scaler, trainData)
testData_scaled  <- predict(scaler, testData)

# ----------------------------------------------------
# 모델 1 (SVM - 11주) - 표준화된 데이터 사용
# ----------------------------------------------------
# (probability=TRUE: 나중에 ROC 커브를 그리기 위함)
model_svm <- svm(diagnosis ~ ., 
                 data = trainData_scaled, 
                 kernel = "radial",  # RBF 커널
                 probability = TRUE)

pred_svm <- predict(model_svm, testData_scaled)
cm_svm <- confusionMatrix(pred_svm, testData_scaled$diagnosis, positive = "Malignant")
print("--- SVM 모델 평가 결과 ---")
print(cm_svm)

# ----------------------------------------------------
# 모델 2 (Random Forest - 10주) - 원본 데이터 사용 (RF는 스케일링 불필요)
# ----------------------------------------------------
model_rf <- randomForest(diagnosis ~ ., 
                         data = trainData, # 스케일링 안 된 데이터 사용
                         ntree = 100)

pred_rf <- predict(model_rf, testData)
cm_rf <- confusionMatrix(pred_rf, testData$diagnosis, positive = "Malignant")
print("--- Random Forest 모델 평가 결과 ---")
print(cm_rf)

# RF 피처 중요도 시각화
varImpPlot(model_rf)


# ----------------------------------------------------
# 모델 3 (PCA + SVM - 9주, 11주) - 표준화된 데이터 사용
# ----------------------------------------------------
# 1. PCA 수행 (표준화된 train 데이터로)
pca_result <- prcomp(trainData_scaled[, feature_names])

# 2. PCA 변환된 데이터 생성
train_pca <- as.data.frame(predict(pca_result, trainData_scaled))
train_pca$diagnosis <- trainData_scaled$diagnosis

test_pca <- as.data.frame(predict(pca_result, testData_scaled))
test_pca$diagnosis <- testData_scaled$diagnosis

# (예: 5개의 주성분만 사용)
num_components <- 5
train_pca_subset <- train_pca[, c(1:num_components, ncol(train_pca))]
test_pca_subset  <- test_pca[, c(1:num_components, ncol(test_pca))]

# 3. PCA 데이터로 SVM 학습
model_pca_svm <- svm(diagnosis ~ ., 
                     data = train_pca_subset, 
                     kernel = "radial")

pred_pca_svm <- predict(model_pca_svm, test_pca_subset)
cm_pca_svm <- confusionMatrix(pred_pca_svm, test_pca_subset$diagnosis, positive = "Malignant")
print("--- PCA + SVM 모델 평가 결과 ---")

# --- 4. 최종 모델 비교 (ROC-AUC) ---

# 4-1. 각 모델의 '악성(Malignant)' 확률 계산
# SVM (probability=TRUE로 학습했어야 함)
prob_svm <- attr(predict(model_svm, testData_scaled, probability = TRUE), "probabilities")
prob_svm_malignant <- prob_svm[, "Malignant"]

# Random Forest
prob_rf <- predict(model_rf, testData, type = "prob")
prob_rf_malignant <- prob_rf[, "Malignant"]

# PCA+SVM (이것도 probability=TRUE로 다시 학습해야 함)
model_pca_svm_prob <- svm(diagnosis ~ ., 
                          data = train_pca_subset, 
                          kernel = "radial",
                          probability = TRUE)
prob_pca_svm <- attr(predict(model_pca_svm_prob, test_pca_subset, probability = TRUE), "probabilities")
prob_pca_svm_malignant <- prob_pca_svm[, "Malignant"]


# 4-2. ROC 커브 계산
roc_svm <- roc(testData$diagnosis, prob_svm_malignant, levels = c("Benign", "Malignant"))
roc_rf  <- roc(testData$diagnosis, prob_rf_malignant, levels = c("Benign", "Malignant"))
roc_pca_svm <- roc(testData$diagnosis, prob_pca_svm_malignant, levels = c("Benign", "Malignant"))

# 4-3. ROC 커브 시각화
plot(roc_svm, col = "blue", main = "ROC Curve Comparison", lwd = 2)
plot(roc_rf, add = TRUE, col = "red", lwd = 2)
plot(roc_pca_svm, add = TRUE, col = "green", lwd = 2)

legend("bottomright", 
       legend = c(paste("SVM (AUC:", round(auc(roc_svm), 3), ")"),
                  paste("RF (AUC:", round(auc(roc_rf), 3), ")"),
                  paste("PCA+SVM (AUC:", round(auc(roc_pca_svm), 3), ")")),
       col = c("blue", "red", "green"),
       lwd = 2)


print(cm_pca_svm)


```

